{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, _`what does Annie wants?`_\n",
    "\n",
    "> She wants to understand her profits and margins, what tasks does she entrusted us?\n",
    "\n",
    "1. Efficiently ingest the relevant csv files into a suitable database.\n",
    "2. Transform the data to calculate profits ($) and margin (%).\n",
    "3. Create a report for Annie outlining:\n",
    "* a. Top 10 products based on profit ($) and margin(%).\n",
    "* b. Top 10 brands based on profit ($) and margin (%).\n",
    "* c. Which brands / products should she drop as a wholesales because they are loosing money."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we want what Annie wants, lets work to make it happen. First we can see that the job will have two parts:\n",
    "1. _`Ingest, explore and transform the data`_: According to the second goal.\n",
    "2. _`Create a BI report for Annie to understand her data`_: Make data accessible to Annie via dashboard on a BI tool for her to understand her data and how business is running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ingest relevant files into a suitable database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would suggest a DB medallion architecture for Business Analytics.\n",
    "\n",
    "`What is a medallion architecture?`:\n",
    "Medallion architecture is a data storing pattern where we store the data following 3 \"medals\" before reaching our analytic goals. These \"medals\" are:\n",
    "1. `Bronze`: We load the data just as we get them into a suitable database or data formats. The goal is to store the data fast, having it in its `raw` state to change a modify the other two medallion in case it is needed. (CSVs into our file system for this case scenario)\n",
    "2. `Silver`: We fetch the data from the bronze medallion, apply transformations and store them into our database. This data is clean and just the relevant information is stored in this \"medallion\". (postgres database running locally)\n",
    "3. `Gold`: The gold medallion is the goal of our Analytical purposes, as it contains the data from the \"silver medal\" with aggregations applied to them, to get only the most useful and \"rich\" data for our Analysis. These could be: Predictions, Flags, Grouping, Calculated new columns, etc. (Materialized views and aggregated data tables).\n",
    "\n",
    "\n",
    "Dev plan:\n",
    "1. `Bronze`: Fetch the csv from the data source, and store them into our file sistem. (csvs would be our bronze medallion).\n",
    "2. `Silver`: After EDA (Exploratory Data Analysis) we will take into account the relevant columns to store into our postgreSQL database.\n",
    "3. `Gold`: We would make calculated and aggregated columns, such as crossed data from distinct tables, calculated columns such as margin and profit (requested by Annie, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bronze.\n",
    "\n",
    "We will fetch the .zips directly from the api and store them into our local file system as zip files to not use too much disk space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First we will create the adapter to make API calls to fetch the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from typing import Any, Dict\n",
    "\n",
    "class APIClient():\n",
    "    def __init__(self, base_url: str):\n",
    "        self.base_url = base_url\n",
    "        self.headers: dict[str,Any] = {}\n",
    "\n",
    "    def make_post_request(\n",
    "        self, \n",
    "        endpoint: str, \n",
    "        **kwargs\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Makes a POST request to the specified endpoint.\n",
    "\n",
    "        Params:\n",
    "            endpoint (str): The API endpoint to which the request is made.\n",
    "            is_root_func (bool, optional): Indicates if this is the root \n",
    "            function call. Defaults to True.\n",
    "            **kwargs: Additional keyword arguments to be sent as JSON in \n",
    "            the request body.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: The JSON response data from the POST request.\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        print(f\"Making a POST request to {url}\", flush=True)\n",
    "        response = requests.post(url, headers=self.headers, data=json.dumps(kwargs))\n",
    "        return response\n",
    "    \n",
    "    def make_get_request(\n",
    "        self, \n",
    "        endpoint: str,\n",
    "        **kwargs\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Makes a GET request to the specified endpoint.\n",
    "\n",
    "        Params:\n",
    "            endpoint (str): The API endpoint to which the request is made.\n",
    "            is_root_func (bool, optional): Indicates if this is the root \n",
    "            function call. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: The JSON response data from the POST request.\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}{endpoint}\"\n",
    "        print(f\"Making a GET request to {url}\", flush=True)\n",
    "        response = requests.get(url, headers=self.headers, params=kwargs)\n",
    "        return response\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now the script to store it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "def save_zip_into_directory(zip_bytes: BytesIO, output_dir: str = \"extracted_files\", zip_filename: str = \"archive.zip\") -> str:\n",
    "    \"\"\"\n",
    "    Saves the ZIP file to the file system.\n",
    "\n",
    "    Args:\n",
    "        zip_bytes (BytesIO): ZIP file data in memory.\n",
    "        output_dir (str): Directory where the ZIP will be saved (default: \"extracted_files\").\n",
    "        zip_filename (str): Name to use for the saved ZIP file (default: \"archive.zip\").\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the saved ZIP file, or None if saving failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        zip_path = os.path.join(output_dir, zip_filename)\n",
    "        with open(zip_path, \"wb\") as f:\n",
    "            f.write(zip_bytes)\n",
    "\n",
    "\n",
    "        print(f\"Successfully saved ZIP to: {zip_path}\", flush=True)\n",
    "        return zip_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving ZIP file: {e}\", flush=True)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* And then we will loop through the availables zips to store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a GET request to https://www.pwc.com/us/en/careers/university_relations/data_analytics_cases_studies/PurchasesFINAL12312016csv.zip\n",
      "Successfully saved ZIP to: data\\PurchasesFINAL12312016csv.zip\n",
      "Making a GET request to https://www.pwc.com/us/en/careers/university_relations/data_analytics_cases_studies/BegInvFINAL12312016csv.zip\n",
      "Successfully saved ZIP to: data\\BegInvFINAL12312016csv.zip\n",
      "Making a GET request to https://www.pwc.com/us/en/careers/university_relations/data_analytics_cases_studies/2017PurchasePricesDeccsv.zip\n",
      "Successfully saved ZIP to: data\\2017PurchasePricesDeccsv.zip\n",
      "Making a GET request to https://www.pwc.com/us/en/careers/university_relations/data_analytics_cases_studies/VendorInvoices12312016csv.zip\n",
      "Successfully saved ZIP to: data\\VendorInvoices12312016csv.zip\n",
      "Making a GET request to https://www.pwc.com/us/en/careers/university_relations/data_analytics_cases_studies/EndInvFINAL12312016csv.zip\n",
      "Successfully saved ZIP to: data\\EndInvFINAL12312016csv.zip\n",
      "Making a GET request to https://www.pwc.com/us/en/careers/university_relations/data_analytics_cases_studies/SalesFINAL12312016csv.zip\n",
      "Successfully saved ZIP to: data\\SalesFINAL12312016csv.zip\n"
     ]
    }
   ],
   "source": [
    "client = APIClient(base_url=\"https://www.pwc.com/us/en/careers/university_relations/data_analytics_cases_studies/\")\n",
    "\n",
    "available_data = {\n",
    "    \"purchases\": \"PurchasesFINAL12312016csv.zip\",\n",
    "    \"beginning_inventory\": \"BegInvFINAL12312016csv.zip\",\n",
    "    \"purchase_prices\": \"2017PurchasePricesDeccsv.zip\",\n",
    "    \"vendor_invoices\": \"VendorInvoices12312016csv.zip\",\n",
    "    \"ending_inventory\": \"EndInvFINAL12312016csv.zip\",\n",
    "    \"sales\": \"SalesFINAL12312016csv.zip\"\n",
    "}\n",
    "\n",
    "for value in available_data.values():\n",
    "    response = client.make_get_request(endpoint=value)\n",
    "    save_zip_into_directory(\n",
    "        zip_bytes = response.content, \n",
    "        output_dir=\"data\", \n",
    "        zip_filename=value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the data as zip files lets procede with the `Exploratory Data Analysis`.\n",
    "\n",
    "## [Go to EDA](eda.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
